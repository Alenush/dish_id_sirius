{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобрабока датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "m = Mystem()\n",
    "regex = re.compile(\"[А-Яа-я:=!\\)\\()A-z\\_\\%/|]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "def key_words_in_df_preparation(data=df):\n",
    "    num_recipes = len(data['list_resipe'])\n",
    "    list_keywords_dict = []\n",
    "    list_ingridients_kset = []\n",
    "    for i in range(0, num_recipes):\n",
    "        data['list_resipe'][i]=''.join(elem for elem in data['list_resipe'][i])\n",
    "        res = words_only(data['list_resipe'][i])\n",
    "        text1 = lemmatize(res)\n",
    "        text1 = text1.split(' ')\n",
    "        fdist1 = nltk.FreqDist(text1)\n",
    "        fdist1 = dict(fdist1)\n",
    "        list_keywords_dict.append(fdist1)\n",
    "        \n",
    "        # ingridient preprocessing\n",
    "        data['list_ingrid'][i] = ''.join(elem +\" \" for elem in data['list_ingrid'][i])\n",
    "        ingridiens = data['list_ingrid'][i]\n",
    "        res_ingrid = words_only(ingridiens)\n",
    "        ingrid_lem = lemmatize(res_ingrid)\n",
    "        ingrid1 = ingrid_lem.split(' ')\n",
    "        set_ingridients = set(ingrid1)\n",
    "        list_ingridients_kset.append(set_ingridients)\n",
    "    data['ingridient_keywords'] = list_ingridients_kset\n",
    "    data['recipes_keywords'] = list_keywords_dict\n",
    "    data.to_csv('eda_bulony_new.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбираем топ 10 рецептов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_relevant_recipes(list_ingridients, data):\n",
    "    \n",
    "    list_recipes = []\n",
    "    list_ingridients_common = []\n",
    "    list_citations_score = []    \n",
    "    result_list_ingridients = {}\n",
    "    \n",
    "    str_ingridients = ''.join(elem + \" \" for elem in test)\n",
    "    normailize_ingrid = words_only(str_ingridients)\n",
    "    normilized_ingrid = lemmatize(normailize_ingrid)\n",
    "    set_model_result = set(normilized_ingrid.split(' '))\n",
    "    \n",
    "    # step by all recipes\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        # number of common ingridients\n",
    "        ingridients_common = len(set_model_result & data['ingridient_keywords'][i])\n",
    "        list_ingridients_common.append(ingridients_common)\n",
    "        # citation score\n",
    "        citation_score = 0\n",
    "        for ingrid in list_ingridients:\n",
    "            try:\n",
    "                citation_score += data['recipes_keywords'][i][ingrid]\n",
    "            except KeyError:\n",
    "                citation_score += 0\n",
    "        list_citations_score.append(citation_score)\n",
    "    \n",
    "    \n",
    "    top_50_ingrid_common = sorted(range(len(list_ingridients_common)), key=lambda i: list_ingridients_common[i])[-50:]\n",
    "    top_50_ingrid_common.reverse()\n",
    "    # Top 50 рецептов с наибольшим совпадением по ингрединтам\n",
    "    \n",
    "    dict_top_elements = dict()\n",
    "    \n",
    "    for j in range(0, len(top_50_ingrid_common)):\n",
    "        top_elements_id = top_50_ingrid_common[j]\n",
    "        dict_top_elements[top_elements_id] = list_ingridients_common[top_elements_id]\n",
    "    max_value = max(dict_top_elements.values())\n",
    "    result_list_ingridients = {key:value for key, value in dict_top_elements.items() if value == max_value}\n",
    "    \n",
    "    dict_top_10 = dict()\n",
    "    for j in list(result_list_ingridients.keys()):\n",
    "        top_10_element_id = list_citations_score[j]\n",
    "        dict_top_10[top_10_element_id] = list_citations_score[top_10_element_id]\n",
    "    top_10_citation_common = dict(Counter(dict_top_10).most_common(10))\n",
    "        \n",
    "    for item in top_10_citation_common:\n",
    "        list_recipes.append(data['list_resipe'][item])\n",
    "    \n",
    "    return list_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
